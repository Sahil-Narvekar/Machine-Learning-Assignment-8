{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What exactly is a feature? Give an example to illustrate your point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In machine learning, features are individual independent variables that act like a input in your system. \n",
    "Actually, while making the predictions, models use such features to make the predictions. And using the \n",
    "feature engineering process, new features can also be obtained from old features in machine learning.\n",
    "Example to predict the price of the house the features would be area of the house,locality of the gouse etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2. What are the various circumstances in which feature construction is required?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature Extraction aims to reduce the number of features in a dataset by creating new features from the \n",
    "existing ones (and then discarding the original features). These new reduced set of features should then \n",
    "be able to summarize most of the information contained in the original set of feature.The technique of \n",
    "extracting the features is useful when you have a large data set and need to reduce the number of resources\n",
    "without losing any important or relevant information. Feature extraction helps to reduce the amount of \n",
    "redundant data from the data set.In the end, the reduction of the data helps to build the model with less\n",
    "machine’s efforts and also increase the speed of learning and generalization steps in the machine \n",
    "learning process.\n",
    "Used in Bag of words in NLP,Image Processing,Auto Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Describe how nominal variables are encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "One hot encoding: Encoding each categorical variable with different Boolean variables (also called dummy \n",
    "variables) which take values 0 or 1, indicating if a category is present in an observation.\n",
    "Integer Encoding / Label Encoding: Replace the categories by a number from 1 to n (or 0 to n-1, \n",
    "depending the implementation), where n is the number of distinct categories of the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Describe how numeric features are converted to categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Consider the height of people are to be converted to categorical features like short medium and tall\n",
    "then the height in inches may be grouped into bins and the frequency may be recorded,or  algorithms \n",
    "like k means clustering may be used to determine the range of the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Describe the feature selection wrapper approach. State the advantages and disadvantages of this\n",
    "approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In wrapper methods, the feature selection process is based on a specific machine learning algorithm that\n",
    "we are trying to fit on a given dataset.It follows a greedy search approach by evaluating all the possible\n",
    "combinations of features against the evaluation criterion. The evaluation criterion is simply the\n",
    "performance measure which depends on the type of problem, for e.g. For regression evaluation criterion\n",
    "can be p-values, R-squared, Adjusted R-squared, similarly for classification the evaluation criterion can\n",
    "be accuracy, precision, recall, f1-score, etc. Finally, it selects the combination of features that gives\n",
    "the optimal results for the specified machine learning algorithm.\n",
    "Advantages\n",
    "They detect the interaction between variables\n",
    "They find the optimal feature subset for the desired machine learning algorithm\n",
    "The wrapper methods usually result in better predictive accuracy than filter methods.\n",
    "Disadvantages\n",
    "Higher risk of over-fitting as compared than deterministic algorithm\n",
    "Computaionally intensive\n",
    "Discriminative power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6. When is a feature considered irrelevant? What can be said to quantify it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A feature is considered irrelevant if it does not add any value to accuracy of the model rather the accur\n",
    "-acy of model increases when that feature is removed then it will be considered irrelevant.We measure the importance of \n",
    "a feature by calculating the increase in the model's prediction error after permuting the feature. A \n",
    "feature is \"important\" if shuffling its values increases the model error, because in this case the model \n",
    "relied on the feature for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7. When is a function considered redundant? What criteria are used to identify features that could\n",
    "be redundant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features are considered redundant if they add no relevant information to your other features, because they \n",
    "are correlated or because they can be obtained by [linear] combination of other features.if two features \n",
    "{X1, X2} are highly correlated, then the two features become redundant features since they have same \n",
    "information in terms of correlation measure. In other words, the correlation measure provides statistical \n",
    "association between any given a pair of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8. What are the various distance measurements used to determine feature similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Euclidean distance is considered the traditional metric for problems with geometry. It can be simply \n",
    "explained as the ordinary distance between two points. It is one of the most used algorithms in the \n",
    "cluster analysis.\n",
    "Manhattan Distance:\n",
    "This determines the absolute difference among the pair of the coordinates.\n",
    "Suppose we have two points P and Q to determine the distance between these points we simply have to\n",
    "calculate the perpendicular distance of the points from X-Axis and Y-Axis.\n",
    "\n",
    "The Jaccard distance measures the similarity of the two data set items as the intersection of those items\n",
    "divided by the union of the data items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9. State difference between Euclidean and Manhattan distances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Euclidean distance is the shortest path between source and destination which is one straight line\n",
    "but Manhattan distance is sum of all the real distances between source(s) and destination(d) and each \n",
    "distance are always the straight lines ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Distinguish between feature transformation and feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature transformation: transformation of data to improve the accuracy of the algorithm\n",
    "Normalization and changing distribution(Scaling)\n",
    "Interactions\n",
    "Filling in the missing values(median filling etc)\n",
    "\n",
    "feature selection: removing unnecessary features.\n",
    "Statistical approaches\n",
    "Selection by modeling\n",
    "Grid search\n",
    "Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11. Make brief notes on any two of the following:\n",
    "\n",
    "1.SVD (Standard Variable Diameter Diameter)\n",
    "\n",
    "2. Collection of features using a hybrid approach\n",
    "\n",
    "3. The width of the silhouette\n",
    "\n",
    "4. Receiver operating characteristic curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Silhouette width is also an estimate of the average distance between clusters.\n",
    "The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other \n",
    "clusters (separation). The silhouette ranges from −1 to +1, where a high value indicates that the object is\n",
    "well matched to its own cluster and poorly matched to neighboring clusters. If most objects have a high\n",
    "value, then the clustering configuration is appropriate. If many points have a low or negative value, then\n",
    "the clustering configuration may have too many or too few clusters.The silhouette can be calculated with \n",
    "any distance metric, such as the Euclidean distance or the Manhattan distance.\n",
    "\n",
    "A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the \n",
    "diagnostic ability of a binary classifier system as its discrimination threshold is varied.\n",
    "An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a \n",
    "classification model at all classification thresholds. This curve plots two parameters: True Positive Rate.\n",
    "False Positive Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
